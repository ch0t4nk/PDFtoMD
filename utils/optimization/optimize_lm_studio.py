# LM Studio Configuration Script
# This script optimizes LM Studio settings for faster processing

import requests
import json
import time

LM_STUDIO_BASE = "http://192.168.56.1:1234"

def test_current_speed():
    """Test current processing speed"""
    print("â±ï¸ Testing current speed...")

    test_payload = {
        "model": "Qwen2-VL-7B-Instruct",
        "messages": [{"role": "user", "content": "Count from 1 to 5."}],
        "max_tokens": 20,
        "temperature": 0.1
    }

    try:
        start_time = time.time()
        response = requests.post(f"{LM_STUDIO_BASE}/v1/chat/completions", json=test_payload, timeout=30)
        end_time = time.time()

        if response.status_code == 200:
            duration = end_time - start_time
            print(f"âœ… Current speed: {duration:.2f} seconds")
            return duration
        else:
            print(f"âŒ Test failed: {response.status_code}")
            return None
    except Exception as e:
        print(f"âŒ Error: {e}")
        return None

def test_optimized_settings():
    """Test with optimized API parameters"""
    print("\nğŸš€ Testing optimized settings...")

    # Test various optimized configurations
    configs = [
        {"max_tokens": 2048, "temperature": 0.1, "name": "Fast Config"},
        {"max_tokens": 1024, "temperature": 0.05, "name": "Ultra Fast"},
        {"max_tokens": 4096, "temperature": 0.2, "name": "Balanced"},
    ]

    best_config = None
    best_time = float('inf')

    for config in configs:
        print(f"\nğŸ§ª Testing {config['name']}:")

        test_payload = {
            "model": "Qwen2-VL-7B-Instruct",
            "messages": [{"role": "user", "content": "Describe a simple electronic circuit."}],
            "max_tokens": config["max_tokens"],
            "temperature": config["temperature"],
            "top_p": 0.9,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }

        try:
            start_time = time.time()
            response = requests.post(f"{LM_STUDIO_BASE}/v1/chat/completions", json=test_payload, timeout=60)
            end_time = time.time()

            if response.status_code == 200:
                duration = end_time - start_time
                result = response.json()
                content = result['choices'][0]['message']['content']

                print(f"   â±ï¸ Time: {duration:.2f}s")
                print(f"   ğŸ“ Length: {len(content)} chars")
                print(f"   ğŸš€ Speed: {len(content)/duration:.1f} chars/sec")

                if duration < best_time:
                    best_time = duration
                    best_config = config

            else:
                print(f"   âŒ Failed: {response.status_code}")

        except Exception as e:
            print(f"   âŒ Error: {e}")

    if best_config:
        print(f"\nğŸ† Best configuration: {best_config['name']}")
        print(f"   Max Tokens: {best_config['max_tokens']}")
        print(f"   Temperature: {best_config['temperature']}")
        print(f"   Time: {best_time:.2f}s")
        return best_config

    return None

def create_optimized_env_file(best_config=None):
    """Create optimized environment file"""
    print("\nğŸ“ Creating optimized settings...")

    # Default optimized settings
    if not best_config:
        best_config = {"max_tokens": 2048, "temperature": 0.1}

    optimized_settings = f'''# Optimized LM Studio Settings
# Generated by check_lm_settings.py

# API Configuration
OPENAI_API_KEY="lm-studio"
OPENAI_API_BASE="http://192.168.56.1:1234/v1"
OPENAI_DEFAULT_MODEL="Qwen2-VL-7B-Instruct"

# Optimized Parameters
OPENAI_MAX_TOKENS="{best_config['max_tokens']}"
OPENAI_TEMPERATURE="{best_config['temperature']}"
OPENAI_TOP_P="0.9"
OPENAI_RETRY_DELAY="0.3"

# Performance Settings
OPENAI_REQUEST_TIMEOUT="60"
OPENAI_BATCH_SIZE="1"
'''

    try:
        with open('.env.optimized', 'w') as f:
            f.write(optimized_settings)
        print("âœ… Created .env.optimized file")
        print("   You can rename this to .env to use optimized settings")
        return True
    except Exception as e:
        print(f"âŒ Error creating file: {e}")
        return False

def show_manual_optimizations():
    """Display manual optimization steps"""
    print("\nğŸ”§ MANUAL LM STUDIO OPTIMIZATIONS:")
    print("=" * 50)
    print()
    print("ğŸ“± In LM Studio GUI:")
    print("   1. Click on your loaded model")
    print("   2. Look for 'Advanced' or 'Parameters' section")
    print("   3. Adjust these settings:")
    print()
    print("ğŸ¯ Key Settings to Find:")
    print("   â€¢ Context Window/Length: 4096 (reduce from 8192+)")
    print("   â€¢ n_gpu_layers: -1 or 99 (use all GPU)")
    print("   â€¢ n_batch: 512-1024 (increase batch size)")
    print("   â€¢ n_threads: 8-16 (half your CPU cores)")
    print("   â€¢ rope_freq_base: 10000 (default)")
    print()
    print("âš¡ Alternative: Look for these in LM Studio:")
    print("   â€¢ 'GPU Acceleration': Max/High")
    print("   â€¢ 'Context Size': 4096")
    print("   â€¢ 'Batch Size': Large/512+")
    print("   â€¢ 'CPU Threads': 8-16")
    print()
    print("ğŸ–¥ï¸ System Optimizations:")
    print("   1. Windows: Set Power Plan to 'High Performance'")
    print("   2. NVIDIA Control Panel â†’ Manage 3D Settings:")
    print("      - Power management: 'Prefer maximum performance'")
    print("   3. Close unnecessary applications")
    print()
    print("ğŸ§ª Testing:")
    print("   â€¢ After changes, restart LM Studio")
    print("   â€¢ Test with a simple prompt first")
    print("   â€¢ Monitor GPU usage with nvidia-smi")

def main():
    print("ğŸš€ LM Studio Optimizer")
    print("=" * 30)

    # Test current speed
    current_speed = test_current_speed()

    # Test optimized API settings
    best_config = test_optimized_settings()

    # Create optimized config file
    create_optimized_env_file(best_config)

    # Show manual steps
    show_manual_optimizations()

    print("\n" + "=" * 50)
    print("âœ… Optimization analysis complete!")

    if current_speed:
        print(f"ğŸ“Š Baseline speed: {current_speed:.2f}s")
        if best_config:
            print(f"ğŸ¯ Target improvement: 2-3x faster")
        print("\nğŸ’¡ Next steps:")
        print("   1. Apply manual LM Studio settings above")
        print("   2. Use .env.optimized for application settings")
        print("   3. Test with convert_fast.py")

if __name__ == "__main__":
    main()
