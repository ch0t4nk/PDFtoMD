# LM Studio Configuration Script
# This script optimizes LM Studio settings for faster processing

import time

import requests

LM_STUDIO_BASE = "http://192.168.56.1:1234"


def test_current_speed():
    """Test current processing speed"""
    print("‚è±Ô∏è Testing current speed...")

    test_payload = {
        "model": "Qwen2-VL-7B-Instruct",
        "messages": [{"role": "user", "content": "Count from 1 to 5."}],
        "max_tokens": 20,
        "temperature": 0.1,
    }

    try:
        start_time = time.time()
        response = requests.post(
            f"{LM_STUDIO_BASE}/v1/chat/completions", json=test_payload, timeout=30
        )
        end_time = time.time()

        if response.status_code == 200:
            duration = end_time - start_time
            print(f"‚úÖ Current speed: {duration:.2f} seconds")
            return duration
        else:
            print(f"‚ùå Test failed: {response.status_code}")
            return None
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return None


def test_optimized_settings():
    """Test with optimized API parameters"""
    print("\nüöÄ Testing optimized settings...")

    # Test various optimized configurations
    configs = [
        {"max_tokens": 2048, "temperature": 0.1, "name": "Fast Config"},
        {"max_tokens": 1024, "temperature": 0.05, "name": "Ultra Fast"},
        {"max_tokens": 4096, "temperature": 0.2, "name": "Balanced"},
    ]

    best_config = None
    best_time = float("inf")

    for config in configs:
        print(f"\nüß™ Testing {config['name']}:")

        test_payload = {
            "model": "Qwen2-VL-7B-Instruct",
            "messages": [
                {"role": "user", "content": "Describe a simple electronic circuit."}
            ],
            "max_tokens": config["max_tokens"],
            "temperature": config["temperature"],
            "top_p": 0.9,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
        }

        try:
            start_time = time.time()
            response = requests.post(
                f"{LM_STUDIO_BASE}/v1/chat/completions", json=test_payload, timeout=60
            )
            end_time = time.time()

            if response.status_code == 200:
                duration = end_time - start_time
                result = response.json()
                content = result["choices"][0]["message"]["content"]

                print(f"   ‚è±Ô∏è Time: {duration:.2f}s")
                print(f"   üìù Length: {len(content)} chars")
                print(f"   üöÄ Speed: {len(content) / duration:.1f} chars/sec")

                if duration < best_time:
                    best_time = duration
                    best_config = config

            else:
                print(f"   ‚ùå Failed: {response.status_code}")

        except Exception as e:
            print(f"   ‚ùå Error: {e}")

    if best_config:
        print(f"\nüèÜ Best configuration: {best_config['name']}")
        print(f"   Max Tokens: {best_config['max_tokens']}")
        print(f"   Temperature: {best_config['temperature']}")
        print(f"   Time: {best_time:.2f}s")
        return best_config

    return None


def create_optimized_env_file(best_config=None):
    """Create optimized environment file"""
    print("\nüìù Creating optimized settings...")

    # Default optimized settings
    if not best_config:
        best_config = {"max_tokens": 2048, "temperature": 0.1}

    optimized_settings = f'''# Optimized LM Studio Settings
# Generated by check_lm_settings.py

# API Configuration
OPENAI_API_KEY="lm-studio"
OPENAI_API_BASE="http://192.168.56.1:1234/v1"
OPENAI_DEFAULT_MODEL="Qwen2-VL-7B-Instruct"

# Optimized Parameters
OPENAI_MAX_TOKENS="{best_config["max_tokens"]}"
OPENAI_TEMPERATURE="{best_config["temperature"]}"
OPENAI_TOP_P="0.9"
OPENAI_RETRY_DELAY="0.3"

# Performance Settings
OPENAI_REQUEST_TIMEOUT="60"
OPENAI_BATCH_SIZE="1"
'''

    try:
        with open(".env.optimized", "w") as f:
            f.write(optimized_settings)
        print("‚úÖ Created .env.optimized file")
        print("   You can rename this to .env to use optimized settings")
        return True
    except Exception as e:
        print(f"‚ùå Error creating file: {e}")
        return False


def show_manual_optimizations():
    """Display manual optimization steps"""
    print("\nüîß MANUAL LM STUDIO OPTIMIZATIONS:")
    print("=" * 50)
    print()
    print("üì± In LM Studio GUI:")
    print("   1. Click on your loaded model")
    print("   2. Look for 'Advanced' or 'Parameters' section")
    print("   3. Adjust these settings:")
    print()
    print("üéØ Key Settings to Find:")
    print("   ‚Ä¢ Context Window/Length: 4096 (reduce from 8192+)")
    print("   ‚Ä¢ n_gpu_layers: -1 or 99 (use all GPU)")
    print("   ‚Ä¢ n_batch: 512-1024 (increase batch size)")
    print("   ‚Ä¢ n_threads: 8-16 (half your CPU cores)")
    print("   ‚Ä¢ rope_freq_base: 10000 (default)")
    print()
    print("‚ö° Alternative: Look for these in LM Studio:")
    print("   ‚Ä¢ 'GPU Acceleration': Max/High")
    print("   ‚Ä¢ 'Context Size': 4096")
    print("   ‚Ä¢ 'Batch Size': Large/512+")
    print("   ‚Ä¢ 'CPU Threads': 8-16")
    print()
    print("üñ•Ô∏è System Optimizations:")
    print("   1. Windows: Set Power Plan to 'High Performance'")
    print("   2. NVIDIA Control Panel ‚Üí Manage 3D Settings:")
    print("      - Power management: 'Prefer maximum performance'")
    print("   3. Close unnecessary applications")
    print()
    print("üß™ Testing:")
    print("   ‚Ä¢ After changes, restart LM Studio")
    print("   ‚Ä¢ Test with a simple prompt first")
    print("   ‚Ä¢ Monitor GPU usage with nvidia-smi")


def main():
    print("üöÄ LM Studio Optimizer")
    print("=" * 30)

    # Test current speed
    current_speed = test_current_speed()

    # Test optimized API settings
    best_config = test_optimized_settings()

    # Create optimized config file
    create_optimized_env_file(best_config)

    # Show manual steps
    show_manual_optimizations()

    print("\n" + "=" * 50)
    print("‚úÖ Optimization analysis complete!")

    if current_speed:
        print(f"üìä Baseline speed: {current_speed:.2f}s")
        if best_config:
            print("üéØ Target improvement: 2-3x faster")
        print("\nüí° Next steps:")
        print("   1. Apply manual LM Studio settings above")
        print("   2. Use .env.optimized for application settings")
        print("   3. Test with convert_fast.py")


if __name__ == "__main__":
    main()
